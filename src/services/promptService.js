/**
 * Servicio de prompts mejorado para el chatbot de WhatsApp ERP
 * Incluye capacidades contextuales para mejor comprensi√≥n conversacional
 */

const fetch = require('node-fetch');
const { logger } = require('../utils/logger');
const { renderTemplate } = require('../utils/promptTemplates');

// Configuraci√≥n del servicio
const CONFIG = {
    maxRetries: 3,
    retryDelay: 2000, // 2 segundos
    timeout: 30000, // 30 segundos
    temperature: 0.2,
    topP: 0.9,
    topK: 40
};

/**
 * Pausa la ejecuci√≥n por un tiempo determinado
 * @param {number} ms - Milisegundos a esperar
 * @returns {Promise}
 */
function sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
}

/**
 * Verifica si el error es debido a que el modelo se est√° cargando
 * @param {string} errorMessage - Mensaje de error
 * @returns {boolean}
 */
function isModelLoadingError(errorMessage) {
    return errorMessage.includes('llm server loading model') || 
           errorMessage.includes('model loading') ||
           errorMessage.includes('server loading') ||
           errorMessage.includes('loading');
}

/**
 * Consulta al modelo LLM usando la API de generate de Ollama
 * @param {Object} promptData - Datos del prompt
 * @param {string} promptData.systemPrompt - Instrucciones del sistema
 * @param {string} promptData.userPrompt - Mensaje del usuario
 * @param {Object} options - Opciones adicionales
 * @returns {Promise<string>} - Respuesta del modelo
 */
async function queryModel(promptData, options = {}) {
    const maxRetries = options.maxRetries || CONFIG.maxRetries;
    
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
        try {
            logger.debug(`Intento ${attempt}/${maxRetries} de consulta al modelo`);
            
            // Combinar system prompt y user prompt para API de generate
            const fullPrompt = promptData.systemPrompt 
                ? `${promptData.systemPrompt}\n\nUsuario: ${promptData.userPrompt}\nAsistente:`
                : promptData.userPrompt;
            
            const requestBody = {
                model: process.env.OLLAMA_MODEL || 'llama3:8b',
                prompt: fullPrompt,
                stream: false,
                options: {
                    temperature: options.temperature || CONFIG.temperature,
                    top_p: CONFIG.topP,
                    top_k: CONFIG.topK,
                    stop: ['\nUsuario:', '\nUser:']
                }
            };
            
            logger.debug(`Enviando request a: ${process.env.OLLAMA_API_URL}/generate`);
            
            const controller = new AbortController();
            const timeoutId = setTimeout(() => controller.abort(), CONFIG.timeout);
            
            const response = await fetch(`${process.env.OLLAMA_API_URL}/generate`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify(requestBody),
                signal: controller.signal
            });
            
            clearTimeout(timeoutId);
            
            if (!response.ok) {
                const errorText = await response.text();
                const error = new Error(`Error HTTP ${response.status}: ${errorText}`);
                
                // Si es error de modelo cargando y no es el √∫ltimo intento
                if (isModelLoadingError(errorText) && attempt < maxRetries) {
                    logger.warn(`Modelo cargando, esperando ${CONFIG.retryDelay * attempt}ms antes del siguiente intento...`);
                    await sleep(CONFIG.retryDelay * attempt);
                    continue;
                }
                
                throw error;
            }
            
            const data = await response.json();
            return data.response || '';
            
        } catch (error) {
            logger.error(`Error en intento ${attempt}/${maxRetries}: ${error.message}`);
            
            // Si es el √∫ltimo intento o no es un error recuperable
            if (attempt === maxRetries || (!isModelLoadingError(error.message) && !error.name === 'AbortError')) {
                if (error.name === 'AbortError') {
                    throw new Error(`Timeout: La respuesta del modelo excedi√≥ el tiempo l√≠mite de ${CONFIG.timeout}ms`);
                }
                throw error;
            }
            
            // Esperar antes del siguiente intento con backoff exponencial
            const delay = CONFIG.retryDelay * Math.pow(2, attempt - 1);
            logger.info(`Esperando ${delay}ms antes del siguiente intento...`);
            await sleep(delay);
        }
    }
    
    throw new Error('Se agotaron todos los intentos de conexi√≥n con Ollama');
}

/**
 * Detecta las intenciones presentes en el mensaje del usuario (sin contexto)
 * @param {string} message - Mensaje del usuario
 * @param {string} templateName - Nombre de la plantilla a usar
 * @param {Object} variables - Variables para la plantilla
 * @param {Object} options - Opciones adicionales
 * @returns {Promise<Object>} - Objeto con las intenciones detectadas
 */
async function detectIntentions(message, templateName = 'intent-detection', variables = {}, options = {}) {
    try {
        const systemPrompt = renderTemplate(
            require('../utils/promptTemplates').baseTemplates[templateName] || 
            require('../utils/promptTemplates').baseTemplates['intent-detection'],
            variables
        );

        const response = await queryModel({
            systemPrompt,
            userPrompt: message
        }, options);
        
        return parseIntentResponse(response);
    } catch (error) {
        logger.error(`Error al detectar intenciones: ${error.message}`);
        return { intents: [] };
    }
}

/**
 * Detecta intenciones considerando el contexto conversacional
 * @param {string} message - Mensaje del usuario
 * @param {Object} context - Contexto conversacional
 * @param {string} templateName - Nombre de la plantilla a usar
 * @param {Object} variables - Variables para la plantilla
 * @param {Object} options - Opciones adicionales
 * @returns {Promise<Object>} - Objeto con las intenciones detectadas
 */
async function detectIntentionsWithContext(message, context, templateName = 'contextual-intent-detection', variables = {}, options = {}) {
    try {
        // Plantilla contextual para detecci√≥n de intenciones
        const contextualTemplate = `
Eres un especialista en an√°lisis de intenciones para un chatbot de WhatsApp que ayuda con un sistema {{serviceType}} empresarial.

### CONTEXTO CONVERSACIONAL ###
{{#if context.userProfile.isRegistered}}
Usuario registrado: {{context.userProfile.name}} ({{context.userProfile.email}})
{{#if context.userProfile.company}}Empresa: {{context.userProfile.company}}{{/if}}
{{#if context.userProfile.position}}Cargo: {{context.userProfile.position}}{{/if}}
{{else}}
Usuario no registrado
{{/if}}

{{#if context.knownEntities}}
Informaci√≥n conocida del usuario:
{{#each context.knownEntities}}
- {{@key}}: {{this}}
{{/each}}
{{/if}}

{{#if context.currentTopic}}
Tema actual de conversaci√≥n: {{context.currentTopic}}
Fuerza del contexto: {{context.contextStrength}}
{{/if}}

{{#if context.recentMessages}}
√öltimos mensajes de la conversaci√≥n:
{{#each context.recentMessages}}
{{#if this.isFromUser}}Usuario{{else}}Bot{{/if}}: "{{this.message}}"
{{/each}}
{{/if}}

{{#if context.recentIntents}}
Intenciones recientes: {{JSON.stringify context.recentIntents}}
{{/if}}

{{#if context.topicHistory}}
Temas previos: {{JSON.stringify context.topicHistory}}
{{/if}}

### INSTRUCCIONES ###
Analiza el mensaje actual del usuario considerando TODO el contexto conversacional.

1. Identifica TODAS las intenciones presentes en el mensaje.
2. Considera si el usuario contin√∫a con el tema actual o cambia de tema.
3. Si hay ambig√ºedad, prioriza la coherencia contextual.
4. Si el usuario confirma algo, considera qu√© est√° confirmando seg√∫n el contexto.

INTENCIONES POSIBLES:
{{#each supportedIntents}}
- {{this}}
{{/each}}

### EJEMPLOS CONTEXTUALES ###

Ejemplo 1 - Continuidad:
Contexto: Usuario pidi√≥ informaci√≥n sobre el ERP, tema actual: service_interest
Usuario: "Me interesa, ¬øc√≥mo puedo probarlo?"
An√°lisis: Contin√∫a tema actual + nueva intenci√≥n solicitud_prueba
Respuesta: {"intents": ["interes_en_servicio", "solicitud_prueba"]}

Ejemplo 2 - Confirmaci√≥n contextual:
Contexto: Bot pregunt√≥ "¬øTu nombre es Juan P√©rez?", usuario conocido: Juan P√©rez
Usuario: "S√≠"
An√°lisis: Confirmaci√≥n del nombre en contexto
Respuesta: {"intents": ["confirmacion"]}

Ejemplo 3 - Cambio de tema:
Contexto: Usuario estaba pidiendo prueba, tema actual: trial_request
Usuario: "Antes de eso, ¬øcu√°nto cuesta?"
An√°lisis: Cambio a consulta de precio
Respuesta: {"intents": ["consulta_precio"]}

### IMPORTANTE ###
- Considera SIEMPRE el contexto conversacional
- Si el usuario dice "s√≠", "correcto", "exacto" ‚Üí probablemente es confirmaci√≥n
- Si contin√∫a el tema actual, incluye intenciones relacionadas
- Si cambia de tema abruptamente, detecta la nueva intenci√≥n principal
- Un mensaje puede tener M√öLTIPLES intenciones simult√°neamente

Formato de respuesta requerido:
{"intents": ["intencion1", "intencion2"]}`;

        const systemPrompt = renderTemplate(contextualTemplate, {
            ...variables,
            context: context
        });

        const response = await queryModel({
            systemPrompt,
            userPrompt: message
        }, options);
        
        const result = parseIntentResponse(response);
        
        // Agregar informaci√≥n contextual al resultado
        return {
            ...result,
            contextUsed: true,
            topicContinuity: context.currentTopic ? 
                result.intents.some(intent => getIntentsForTopic(context.currentTopic).includes(intent)) : 
                false
        };
    } catch (error) {
        logger.error(`Error al detectar intenciones con contexto: ${error.message}`);
        // Fallback a detecci√≥n sin contexto
        return await detectIntentions(message, 'intent-detection', variables, options);
    }
}

/**
 * Extrae entidades relevantes del mensaje del usuario (sin contexto)
 * @param {string} message - Mensaje del usuario
 * @param {string} templateName - Nombre de la plantilla a usar
 * @param {Object} variables - Variables para la plantilla
 * @param {Object} options - Opciones adicionales
 * @returns {Promise<Object>} - Objeto con las entidades extra√≠das
 */
async function extractEntities(message, templateName = 'entity-extraction', variables = {}, options = {}) {
    try {
        const systemPrompt = renderTemplate(
            require('../utils/promptTemplates').baseTemplates[templateName] || 
            require('../utils/promptTemplates').baseTemplates['entity-extraction'],
            variables
        );

        const response = await queryModel({
            systemPrompt,
            userPrompt: message
        }, options);
        
        return parseEntityResponse(response);
    } catch (error) {
        logger.error(`Error al extraer entidades: ${error.message}`);
        return {};
    }
}

/**
 * Extrae entidades considerando el contexto conversacional
 * @param {string} message - Mensaje del usuario
 * @param {Object} context - Contexto conversacional
 * @param {string} templateName - Nombre de la plantilla a usar
 * @param {Object} variables - Variables para la plantilla
 * @param {Object} options - Opciones adicionales
 * @returns {Promise<Object>} - Objeto con las entidades extra√≠das
 */
async function extractEntitiesWithContext(message, context, templateName = 'contextual-entity-extraction', variables = {}, options = {}) {
    try {
        // Plantilla contextual para extracci√≥n de entidades
        const contextualTemplate = `
Eres un especialista en extracci√≥n de entidades para un chatbot empresarial de WhatsApp.

### CONTEXTO CONVERSACIONAL ###
{{#if context.userProfile.isRegistered}}
Usuario registrado: {{context.userProfile.name}} ({{context.userProfile.email}})
{{#if context.userProfile.company}}Empresa: {{context.userProfile.company}}{{/if}}
{{#if context.userProfile.position}}Cargo: {{context.userProfile.position}}{{/if}}
{{else}}
Usuario no registrado
{{/if}}

{{#if context.knownEntities}}
Entidades ya conocidas del usuario:
{{#each context.knownEntities}}
- {{@key}}: {{this}}
{{/each}}
{{/if}}

{{#if context.recentMessages}}
√öltimos mensajes de la conversaci√≥n:
{{#each context.recentMessages}}
{{#if this.isFromUser}}Usuario{{else}}Bot{{/if}}: "{{this.message}}"
{{/each}}
{{/if}}

### INSTRUCCIONES ###
Extrae SOLO las entidades nuevas o actualizadas presentes en el mensaje actual.

ENTIDADES A BUSCAR:
{{#each supportedEntities}}
- {{this}}
{{/each}}

### REGLAS ESPECIALES ###
1. NO repitas entidades que ya est√°n en el contexto a menos que el usuario las est√© corrigiendo
2. Si el usuario dice "mi nombre es..." pero ya conocemos su nombre, consid√©ralo como correcci√≥n
3. Si el usuario confirma informaci√≥n ("s√≠", "correcto"), NO extraigas entidades a menos que agregue informaci√≥n nueva
4. Prioriza informaci√≥n expl√≠cita sobre impl√≠cita
5. Si hay ambig√ºedad, no asumas

### EJEMPLOS CONTEXTUALES ###

Ejemplo 1 - Nueva informaci√≥n:
Contexto conocido: nombre="Juan P√©rez"
Usuario: "Mi email es juan@empresa.com"
Extraer: {"email": "juan@empresa.com"}

Ejemplo 2 - Confirmaci√≥n sin nueva info:
Contexto conocido: nombre="Juan P√©rez"
Usuario: "S√≠, ese es mi nombre"
Extraer: {} (no hay entidades nuevas)

Ejemplo 3 - Correcci√≥n:
Contexto conocido: nombre="Juan P√©rez"
Usuario: "Perd√≥n, mi nombre es Juan Carlos P√©rez"
Extraer: {"nombre": "Juan Carlos P√©rez"}

Ejemplo 4 - Credenciales juntas:
Usuario: "usuario123 MiClave456!"
Extraer: {"usuario": "usuario123", "clave": "MiClave456!"}

### IMPORTANTE ###
- Solo incluye entidades que REALMENTE encuentres en el mensaje actual
- No inventes informaci√≥n que no est√© presente
- Considera el contexto para evitar duplicar informaci√≥n conocida
- Responde √öNICAMENTE con JSON v√°lido

Formato de respuesta requerido:
{"entidad": "valor"}`;

        const systemPrompt = renderTemplate(contextualTemplate, {
            ...variables,
            context: context
        });

        const response = await queryModel({
            systemPrompt,
            userPrompt: message
        }, options);
        
        const result = parseEntityResponse(response);
        
        return result;
    } catch (error) {
        logger.error(`Error al extraer entidades con contexto: ${error.message}`);
        // Fallback a extracci√≥n sin contexto
        return await extractEntities(message, 'entity-extraction', variables, options);
    }
}

/**
 * Genera una respuesta contextual para el usuario
 * @param {string} message - Mensaje original del usuario
 * @param {Array} intents - Intenciones detectadas
 * @param {Object} entities - Entidades extra√≠das
 * @param {Object} userData - Informaci√≥n del usuario
 * @param {Object} conversationContext - Contexto de la conversaci√≥n
 * @param {Object} options - Opciones adicionales
 * @returns {Promise<string>} - Respuesta generada
 */
async function generateResponse(message, intents, entities, userData = null, conversationContext = {}, options = {}) {
    try {
        const systemPrompt = `Eres un asistente virtual profesional de WhatsApp para un sistema ERP empresarial llamado "ERP Demo".

Tu trabajo es ayudar a los usuarios con:
- Informaci√≥n sobre el servicio ERP
- Crear cuentas de prueba gratuitas (7 d√≠as)
- Resolver dudas t√©cnicas b√°sicas
- Proporcionar informaci√≥n de contacto para soporte avanzado

CONTEXTO ACTUAL:
- Mensaje del usuario: "${message}"
- Intenciones detectadas: ${JSON.stringify(intents)}
- Entidades extra√≠das: ${JSON.stringify(entities)}
- Usuario existente: ${userData ? `${userData.name} (${userData.email})` : 'No registrado'}
- Estado de conversaci√≥n: ${conversationContext.conversationState || 'Ninguno'}
- Tema actual: ${conversationContext.currentTopic || 'General'}

${userData ? `
INFORMACI√ìN DEL USUARIO:
- Nombre: ${userData.name}
- Email: ${userData.email}
- Empresa: ${userData.company || 'No especificada'}
- Cargo: ${userData.position || 'No especificado'}
` : ''}

CARACTER√çSTICAS DEL ERP:
- Gesti√≥n de inventario
- Facturaci√≥n electr√≥nica
- Contabilidad integrada
- Recursos humanos
- Informes en tiempo real
- Integraci√≥n con bancos
- M√∫ltiples usuarios y permisos

INSTRUCCIONES:
1. Responde de forma amigable y profesional
2. S√© conciso pero informativo (m√°ximo 3-4 oraciones)
3. Si el usuario solicita una prueba, gu√≠alo para obtener: nombre, email, usuario deseado y contrase√±a
4. Para soporte t√©cnico, solicita m√°s detalles y proporciona contacto: soporte@erp-demo.ejemplo.com
5. Para precios, menciona que depende del n√∫mero de usuarios y m√≥dulos, y que contacten a ventas@erp-demo.ejemplo.com
6. Si falta informaci√≥n para crear cuenta, pregunta espec√≠ficamente por lo que falta
7. Usa un tono profesional pero cercano
8. No uses emojis excesivos (m√°ximo 1-2 por mensaje)
9. Si conoces informaci√≥n del usuario, √∫sala apropiadamente en tu respuesta

MANEJO DE CONFIRMACIONES:
- Si el usuario confirma ("s√≠", "correcto", "exacto") y hay un flujo activo, contin√∫a el proceso
- Si el usuario confirma informaci√≥n personal, agradece y contin√∫a

EJEMPLOS DE RESPUESTAS:
- Saludo: "${userData ? `¬°Hola ${userData.name}!` : '¬°Hola!'} Soy el asistente virtual de ERP Demo. ¬øEn qu√© puedo ayudarte hoy?"
- Inter√©s: "Me alegra tu inter√©s en ERP Demo${userData && userData.company ? ` para ${userData.company}` : ''}. Nuestro sistema incluye gesti√≥n completa de inventario, facturaci√≥n, contabilidad y m√°s. ¬øTe gustar√≠a una prueba gratuita de 7 d√≠as?"
- Solicitud prueba: "Perfecto${userData ? `, ${userData.name}` : ''}. Puedo crear tu cuenta de prueba. ${userData && userData.email ? 'Ya tengo tu informaci√≥n de contacto.' : 'Necesito tu nombre completo y email.'} ¬øQu√© nombre de usuario y contrase√±a te gustar√≠a usar?"

Responde de manera natural al mensaje del usuario considerando toda la informaci√≥n proporcionada.`;

        const response = await queryModel({
            systemPrompt,
            userPrompt: `Genera una respuesta apropiada para este contexto.`
        }, {
            ...options,
            temperature: 0.7 // Temperatura m√°s alta para respuestas m√°s creativas
        });
        
        return response.trim();
    } catch (error) {
        logger.error(`Error al generar respuesta: ${error.message}`);
        return "Lo siento, estoy teniendo problemas t√©cnicos en este momento. Por favor, intenta de nuevo m√°s tarde o contacta a nuestro equipo de soporte.";
    }
}

/**
 * Obtiene las intenciones relacionadas con un tema espec√≠fico
 * @param {string} topic - Tema actual
 * @returns {Array} - Intenciones relacionadas
 */
function getIntentsForTopic(topic) {
    const topicIntentMapping = {
        'trial_request': ['solicitud_prueba', 'confirmacion', 'interes_en_servicio'],
        'technical_support': ['soporte_tecnico', 'queja'],
        'pricing_inquiry': ['consulta_precio', 'interes_en_servicio'],
        'features_inquiry': ['consulta_caracteristicas', 'interes_en_servicio'],
        'complaint': ['queja', 'soporte_tecnico', 'cancelacion'],
        'cancellation': ['cancelacion', 'queja'],
        'service_interest': ['interes_en_servicio', 'consulta_caracteristicas', 'consulta_precio'],
        'greeting': ['saludo', 'interes_en_servicio'],
        'farewell': ['despedida', 'agradecimiento'],
        'gratitude': ['agradecimiento', 'despedida'],
        'confirmation': ['confirmacion'],
        'general': ['saludo', 'despedida', 'interes_en_servicio', 'solicitud_prueba', 'confirmacion', 'agradecimiento', 'soporte_tecnico', 'consulta_precio', 'consulta_caracteristicas', 'queja', 'cancelacion']
    };
    
    return topicIntentMapping[topic] || [];
}

/**
 * Parsea la respuesta del modelo para extraer intenciones
 * @param {string} response - Respuesta del modelo
 * @returns {Object} - Objeto con intenciones detectadas
 */
function parseIntentResponse(response) {
    try {
        // Buscar JSON en la respuesta
        const jsonMatch = response.match(/\{[^}]*"intents"[^}]*\}/);
        if (!jsonMatch) {
            logger.debug(`No se encontr√≥ JSON v√°lido en respuesta de intenciones: ${response}`);
            return { intents: [] };
        }
        
        const parsed = JSON.parse(jsonMatch[0]);
        
        // Validar que intents sea un array
        if (!Array.isArray(parsed.intents)) {
            logger.warn(`Intents no es un array: ${JSON.stringify(parsed)}`);
            return { intents: [] };
        }
        
        // Filtrar intenciones v√°lidas
        const validIntents = [
            'saludo', 'despedida', 'interes_en_servicio', 'solicitud_prueba', 
            'confirmacion', 'agradecimiento', 'soporte_tecnico', 'consulta_precio', 
            'consulta_caracteristicas', 'queja', 'cancelacion'
        ];
        
        const filteredIntents = parsed.intents.filter(intent => 
            validIntents.includes(intent)
        );
        
        return { intents: filteredIntents };
    } catch (error) {
        logger.debug(`Error parseando intenciones: ${error.message}`);
        return { intents: [] };
    }
}

/**
 * Parsea la respuesta del modelo para extraer entidades
 * @param {string} response - Respuesta del modelo
 * @returns {Object} - Objeto con entidades extra√≠das
 */
function parseEntityResponse(response) {
    try {
        // Si la respuesta indica expl√≠citamente que no hay entidades
        if (response.toLowerCase().includes('no se encontraron entidades') || 
            response.toLowerCase().includes('no hay entidades') ||
            response.toLowerCase().includes('no entities found') ||
            response.toLowerCase().includes('objeto vac√≠o')) {
            return {};
        }
        
        // Buscar JSON en la respuesta
        const jsonMatch = response.match(/\{[^}]*\}/);
        if (!jsonMatch) {
            logger.debug(`No se encontr√≥ JSON v√°lido en respuesta de entidades: ${response}`);
            return {};
        }
        
        const parsed = JSON.parse(jsonMatch[0]);
        
        // Validar que sea un objeto
        if (typeof parsed !== 'object' || parsed === null || Array.isArray(parsed)) {
            logger.debug(`Respuesta de entidades no es un objeto v√°lido: ${typeof parsed}`);
            return {};
        }
        
        // Filtrar solo entidades v√°lidas y limpiar valores
        const validEntities = [
            'nombre', 'email', 'usuario', 'clave', 'empresa', 
            'telefono', 'cargo', 'industria', 'numero_empleados'
        ];
        
        const filtered = {};
        
        for (const [key, value] of Object.entries(parsed)) {
            if (validEntities.includes(key) && value && typeof value === 'string') {
                const cleanValue = value.trim();
                if (cleanValue.length > 0) {
                    filtered[key] = cleanValue;
                }
            }
        }
        
        return filtered;
    } catch (error) {
        logger.debug(`Error parseando entidades (normal si no hay entidades): ${error.message}`);
        return {};
    }
}

/**
 * Prueba la conexi√≥n con el servicio de Ollama
 * @returns {Promise<boolean>} - true si la conexi√≥n es exitosa
 */
async function testConnection() {
    try {
        logger.info('üîÑ Probando conexi√≥n con Ollama...');
        
        const response = await queryModel({
            systemPrompt: 'Responde con exactamente estas palabras: "Conexi√≥n exitosa"',
            userPrompt: 'Hola'
        }, {
            maxRetries: 1,
            timeout: 10000
        });
        
        if (response.toLowerCase().includes('conexi√≥n exitosa')) {
            logger.info(`‚úÖ Conexi√≥n con Ollama exitosa: ${response.trim()}`);
            return true;
        } else {
            logger.warn(`‚ö†Ô∏è Respuesta inesperada de Ollama: ${response}`);
            return false;
        }
    } catch (error) {
        logger.error(`‚ùå Error en prueba de conexi√≥n: ${error.message}`);
        return false;
    }
}

/**
 * Obtiene informaci√≥n sobre el modelo actual
 * @returns {Promise<Object>} - Informaci√≥n del modelo
 */
async function getModelInfo() {
    try {
        const response = await fetch(`${process.env.OLLAMA_API_URL}/show`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ name: process.env.OLLAMA_MODEL || 'llama3:8b' })
        });
        
        if (response.ok) {
            const data = await response.json();
            return {
                model: data.model,
                size: data.size,
                parameters: data.parameters,
                template: data.template
            };
        } else {
            throw new Error(`Error HTTP ${response.status}`);
        }
    } catch (error) {
        logger.error(`Error obteniendo informaci√≥n del modelo: ${error.message}`);
        return null;
    }
}

// Exportar todas las funciones
module.exports = {
    queryModel,
    detectIntentions,
    detectIntentionsWithContext,
    extractEntities,
    extractEntitiesWithContext,
    generateResponse,
    parseIntentResponse,
    parseEntityResponse,
    testConnection,
    getModelInfo,
    getIntentsForTopic,
    CONFIG
};